{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MuJDvmDt3yd8",
    "outputId": "3f648eed-c6e8-4e7a-8ce7-a26f42858a0a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Yo27iZ2M4vN7",
    "outputId": "d60a2243-9a9f-4eae-f28c-993515a8975c"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.16.1\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UaxL23Ki4ypZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6kxIuAC_TAI"
   },
   "source": [
    "Import hand-crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EKhuo49S6nVA"
   },
   "outputs": [],
   "source": [
    "handcrafted_features = np.loadtxt('handcrafted.txt', skiprows=1, delimiter='\\t', usecols=(1,2,3,4,5,6,7,8,9,10,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "de4m6WSEMik8"
   },
   "outputs": [],
   "source": [
    "handcrafted_features = np.delete(handcrafted_features, 6, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kh6OAtjq6ntd"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "hf = handcrafted_features\n",
    "for i in range(hf.shape[1]):\n",
    "    tmp_hf = hf[:, i]\n",
    "    tmp_hf = (tmp_hf - min(tmp_hf)) / (max(tmp_hf) - min(tmp_hf))\n",
    "    hf[:, i] = tmp_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9IxBPjd_VJH"
   },
   "source": [
    "Import sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T-qRTKtxFX_h"
   },
   "outputs": [],
   "source": [
    "semantic_contents = np.load('/content/drive/My Drive/Graduate Thesis/Semantic Model/word embedding/set1_data.npy')\n",
    "semantic_labels = np.load('/content/drive/My Drive/Graduate Thesis/Semantic Model/word embedding/set1_label.npy')\n",
    "\n",
    "semantic_lengths = []\n",
    "for i in range(len(semantic_contents)):\n",
    "    semantic_lengths.append(len(semantic_contents[i]))\n",
    "semantic_lengths = np.array(semantic_lengths)\n",
    "semantic_max_length = max(semantic_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lrbY_XWxGUZD"
   },
   "outputs": [],
   "source": [
    "tmp = [0] * 768\n",
    "for i in range(len(semantic_contents)):\n",
    "  length = len(semantic_contents[i])\n",
    "  if length < semantic_max_length:\n",
    "    tmp_ = np.tile(tmp, (semantic_max_length - length, 1))\n",
    "    semantic_contents[i] = np.append(semantic_contents[i], tmp_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Aq77T_0xGwO2"
   },
   "outputs": [],
   "source": [
    "semantic_data = [semantic_contents[0]]\n",
    "for i in range(1, len(semantic_contents)):\n",
    "    semantic_data = np.concatenate((semantic_data, [semantic_contents[i]]), axis=0)\n",
    "semantic_contents = semantic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R5y4qLzRHbwj"
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/My Drive/XGBoost Model/data/semantic_data', semantic_contents)\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/semantic_label', semantic_labels)\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/semantic_length', semantic_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "reG7g7NBAzSE"
   },
   "outputs": [],
   "source": [
    "semantic_contents = np.load('/content/drive/My Drive/XGBoost Model/data/semantic_data.npy')\n",
    "semantic_labels = np.load('/content/drive/My Drive/XGBoost Model/data/semantic_label.npy')\n",
    "semantic_lengths = np.load('/content/drive/My Drive/XGBoost Model/data/semantic_length.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h_ADa9USH4xe"
   },
   "outputs": [],
   "source": [
    "# Calculate rate\n",
    "label_rate = []\n",
    "for i in range(0, 13):\n",
    "    label_rate.append(np.sum(semantic_labels==i))\n",
    "label_rate = np.array(label_rate)\n",
    "label_rate = label_rate / (len(semantic_labels))\n",
    "\n",
    "label_rates = []\n",
    "for i in range(len(semantic_labels)):\n",
    "    label_rates.append(label_rate[int(semantic_labels[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fUthL-PL_Sa8"
   },
   "outputs": [],
   "source": [
    "prompt_contents = np.load('/content/drive/My Drive/Prompt-related Model/word embedding/set1_gold_data.npy')\n",
    "prompt_labels = np.load('/content/drive/My Drive/Prompt-related Model/word embedding/set1_gold_label.npy')\n",
    "\n",
    "prompt_lengths = []\n",
    "for i in range(len(prompt_contents)):\n",
    "    prompt_lengths.append(len(prompt_contents[i]))\n",
    "prompt_lengths = np.array(prompt_lengths)\n",
    "prompt_max_length = max(prompt_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vfswUIpMDngg"
   },
   "outputs": [],
   "source": [
    "tmp = [0] * 768\n",
    "for i in range(len(prompt_contents)):\n",
    "    length = len(prompt_contents[i])\n",
    "    if length < prompt_max_length:\n",
    "        tmp_ = np.tile(tmp, (prompt_max_length - length, 1))\n",
    "        prompt_contents[i] = np.append(prompt_contents[i], tmp_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "s4iJlYPyD3lG"
   },
   "outputs": [],
   "source": [
    "prompt_data = [prompt_contents[0]]\n",
    "for i in range(1, len(prompt_contents)):\n",
    "    prompt_data = np.concatenate((prompt_data, [prompt_contents[i]]), axis=0)\n",
    "prompt_contents = prompt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9EMHr3mAHto9"
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/My Drive/XGBoost Model/data/prompt_data', prompt_contents)\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/prompt_label', prompt_labels)\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/prompt_length', prompt_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qYqHCNgdAjNA"
   },
   "outputs": [],
   "source": [
    "prompt_contents = np.load('/content/drive/My Drive/XGBoost Model/data/prompt_data.npy')\n",
    "prompt_labels = np.load('/content/drive/My Drive/XGBoost Model/data/prompt_label.npy')\n",
    "prompt_lengths = np.load('/content/drive/My Drive/XGBoost Model/data/prompt_length.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M4rkswI9IWv1"
   },
   "outputs": [],
   "source": [
    "def batch_iter(gold_data, gold_labels, gold_lengths, \n",
    "               gold_rate, batch_size, num_epochs):\n",
    "\n",
    "\n",
    "    assert len(gold_data) == len(gold_labels) == len(gold_lengths) == len(gold_rate)\n",
    "    data_size = len(gold_data)\n",
    "\n",
    "    epoch_length = data_size // batch_size\n",
    "  \n",
    "    for _ in range(num_epochs):\n",
    "        for i in range(epoch_length):\n",
    "            start_index = i * batch_size\n",
    "            end_index = start_index + batch_size\n",
    "\n",
    "            xdata = gold_data[start_index: end_index]\n",
    "            ydata = gold_labels[start_index: end_index]\n",
    "            sequence_length = gold_lengths[start_index: end_index]\n",
    "            rate = gold_rate[start_index: end_index]\n",
    "            \n",
    "            yield xdata, ydata, sequence_length, rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBuGpa_SJPaf"
   },
   "source": [
    "Import pre-trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TyhWbqUgMs9K"
   },
   "outputs": [],
   "source": [
    "# Import QWK-relative package\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/ASAPAES')\n",
    "import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MN02fIKfJKf5",
    "outputId": "11fd70e7-9ef0-425f-8275-003b85458db7"
   },
   "outputs": [],
   "source": [
    "# Semantic Model\n",
    "min_val = 2\n",
    "max_val = 12\n",
    "inference_graph = tf.Graph()\n",
    "with tf.Session(graph = inference_graph) as sess:\n",
    "  \n",
    "    graph = tf.get_default_graph()\n",
    "    path = '/content/drive/My Drive/Semantic Model/runs/LSTM/'\n",
    "\n",
    "  \n",
    "    for i in range(3,4):\n",
    "        print(\"No.\" + str(i) + \" Model\\n\")\n",
    "        lstm_model = tf.train.import_meta_graph(os.path.join(path, \"Model_\"+str(i), \"model\", \"clf-300.meta\"))\n",
    "        lstm_model.restore(sess, tf.train.latest_checkpoint(os.path.join(path, \"Model_\"+str(i), \"model\")))\n",
    "    \n",
    "        x_dev = semantic_contents\n",
    "        y_dev = (semantic_labels - min_val) / (max_val - min_val)\n",
    "        dev_lengths = semantic_lengths\n",
    "        dev_rates = label_rates\n",
    "\n",
    "        print('\\nDevlopment Set Validation ' + str(i))\n",
    "        dev_data = batch_iter(x_dev, y_dev, dev_lengths, dev_rates, 1783, 1)\n",
    "        for dev_input in dev_data:\n",
    "      \n",
    "            x_ = inference_graph.get_tensor_by_name('input_x:0')\n",
    "            y_ = inference_graph.get_tensor_by_name('input_y:0')\n",
    "            rate_ = inference_graph.get_tensor_by_name('rate:0')\n",
    "            prediction_ = inference_graph.get_tensor_by_name('sigmoid/predictions:0')\n",
    "            keep_prob_ = inference_graph.get_tensor_by_name('keep_prob:0')\n",
    "            loss_ = inference_graph.get_tensor_by_name('loss/loss:0')\n",
    "            accuracy_ = inference_graph.get_tensor_by_name('accuracy/accuracy:0')\n",
    "            sequence_length_ = inference_graph.get_tensor_by_name('sequence_length:0')\n",
    "            batch_size_ = inference_graph.get_tensor_by_name('batch_size:0')\n",
    "            vars = sess.run([accuracy_, loss_, prediction_], \n",
    "                      feed_dict={x_: dev_input[0],\n",
    "                                 y_: dev_input[1],\n",
    "                                 keep_prob_: 1.0,\n",
    "                                 sequence_length_: dev_input[2],\n",
    "                                 rate_: dev_input[3],\n",
    "                                 batch_size_ : 1783})\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(np.round(vars[2]*10+2))\n",
    "            print (dev_input[1]*10+2)\n",
    "            qwks = score.quadratic_weighted_kappa(np.round((vars[2]*10+2)).astype(int), (dev_input[1]*10+2).astype(int), 2, 12)\n",
    "            print(\"qwks\",qwks,\" \", score.mean_quadratic_weighted_kappa([qwks]))\n",
    "            acc = np.sum(((np.round(vars[2]*10+2)-(dev_input[1]*10+2))==0)==True) / len(vars[2])\n",
    "            print(\"{}: loss: {:g}, accuracy: {:g}\".format(time_str, vars[1], acc))\n",
    "            print('End Development Set Validation ' + str(i) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jx4QzLxTSosv"
   },
   "outputs": [],
   "source": [
    "semantic_prediction_LSTM = vars[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hpwtVRXwD6SR"
   },
   "outputs": [],
   "source": [
    "semantic_prediction_Bi_LSTM = vars[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eymv_F42F-95"
   },
   "outputs": [],
   "source": [
    "def batch_iter_coherence(gold_data, gold_labels, gold_lengths, \n",
    "               gold_rate, batch_size, num_epochs):\n",
    "\n",
    "    assert len(gold_data) == len(gold_labels) == len(gold_lengths) == len(gold_rate)\n",
    "    data_size = len(gold_data)\n",
    "\n",
    "    epoch_length = data_size // batch_size + 1\n",
    "    gold_data = np.concatenate((gold_data, gold_data[0:batch_size]), axis = 0)\n",
    "    gold_labels = np.concatenate((gold_labels, gold_labels[0:batch_size]), axis = 0)\n",
    "    gold_lengths = np.concatenate((gold_lengths, gold_lengths[0:batch_size]), axis = 0)\n",
    "    gold_rate = np.concatenate((gold_rate, gold_rate[0:batch_size]), axis = 0)\n",
    "  \n",
    "    for _ in range(num_epochs):\n",
    "        for i in range(epoch_length):\n",
    "            start_index = i * batch_size\n",
    "            end_index = start_index + batch_size\n",
    "\n",
    "            xdata = gold_data[start_index: end_index]\n",
    "            ydata = gold_labels[start_index: end_index]\n",
    "            sequence_length = gold_lengths[start_index: end_index]\n",
    "            rate = gold_rate[start_index: end_index]\n",
    "            \n",
    "            yield xdata, ydata, sequence_length, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3196
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "r31PMKw1ERHt",
    "outputId": "554a6559-0119-4ab5-da74-9e16a2f9a228"
   },
   "outputs": [],
   "source": [
    "# Coherence Model\n",
    "min_val = 0\n",
    "max_val = 12\n",
    "inference_graph = tf.Graph()\n",
    "res = np.array([])\n",
    "with tf.Session(graph = inference_graph) as sess:\n",
    "  \n",
    "    graph = tf.get_default_graph()\n",
    "    path = '/content/drive/My Drive/Coherence Model/runs/Bi-LSTM/'\n",
    "\n",
    "  \n",
    "    for i in range(2,3):\n",
    "        print(\"No.\" + str(i) + \" Model\\n\")\n",
    "        lstm_model = tf.train.import_meta_graph(os.path.join(path, \"Model_\"+str(i), \"model\", \"clf-500.meta\"))\n",
    "        lstm_model.restore(sess, tf.train.latest_checkpoint(os.path.join(path, \"Model_\"+str(i), \"model\")))\n",
    "    \n",
    "        x_dev = semantic_contents\n",
    "        y_dev = semantic_labels\n",
    "        dev_lengths = semantic_lengths\n",
    "        dev_rates = label_rates\n",
    "\n",
    "        print('\\nDevlopment Set Validation ' + str(i))\n",
    "        dev_data = batch_iter_coherence(x_dev, y_dev, dev_lengths, dev_rates, 256, 1)\n",
    "        for dev_input in dev_data:\n",
    "      \n",
    "            x_ = inference_graph.get_tensor_by_name('input_x:0')\n",
    "            y_ = inference_graph.get_tensor_by_name('input_y:0')\n",
    "            rate_ = inference_graph.get_tensor_by_name('rate:0')\n",
    "            prediction_ = inference_graph.get_tensor_by_name('sigmoid/predictions:0')\n",
    "            keep_prob_ = inference_graph.get_tensor_by_name('keep_prob:0')\n",
    "            loss_ = inference_graph.get_tensor_by_name('loss/loss:0')\n",
    "            accuracy_ = inference_graph.get_tensor_by_name('accuracy/accuracy:0')\n",
    "            sequence_length_ = inference_graph.get_tensor_by_name('sequence_length:0')\n",
    "            batch_size_ = inference_graph.get_tensor_by_name('batch_size:0')\n",
    "            vars = sess.run([accuracy_, loss_, prediction_], \n",
    "                      feed_dict={x_: dev_input[0],\n",
    "                                 y_: dev_input[1],\n",
    "                                 keep_prob_: 1.0,\n",
    "                                 sequence_length_: dev_input[2],\n",
    "                                 rate_: dev_input[3],\n",
    "                                 batch_size_ : 256})\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            res = np.concatenate((res, vars[2]), axis = 0)\n",
    "            print(vars[2])\n",
    "            print (dev_input[1])\n",
    "            qwks = score.quadratic_weighted_kappa((vars[2]).astype(int), dev_input[1], 2, 12)\n",
    "            print(\"qwks\",qwks,\" \", score.mean_quadratic_weighted_kappa([qwks]))\n",
    "            acc = np.sum(((vars[2]-dev_input[1])==0)==True) / len(vars[2])\n",
    "            print(\"{}: loss: {:g}, accuracy: {:g}\".format(time_str, vars[1], acc))\n",
    "            print('End Development Set Validation ' + str(i) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "rwyF_OkgHQF4",
    "outputId": "0633da02-90a1-449f-863f-ec7db0f4c408"
   },
   "outputs": [],
   "source": [
    "coherence_prediction_Bi_LSTM = res[0:1783]\n",
    "qwks = score.quadratic_weighted_kappa(coherence_prediction_Bi_LSTM.astype(int), semantic_labels.astype(int), 2, 12)\n",
    "print(\"qwks\", qwks, \" \", score.mean_quadratic_weighted_kappa([qwks]))\n",
    "acc = np.sum(((coherence_prediction_Bi_LSTM - semantic_labels)==0)==True) / len(semantic_labels)\n",
    "print(\"acc \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "W80ajHK-Igmk",
    "outputId": "837aa733-2734-4e00-dc88-e6b4fa09b7ab"
   },
   "outputs": [],
   "source": [
    "coherence_prediction_LSTM = res[0:1783]\n",
    "qwks = score.quadratic_weighted_kappa(coherence_prediction_LSTM.astype(int), semantic_labels.astype(int), 2, 12)\n",
    "print(\"qwks\", qwks, \" \", score.mean_quadratic_weighted_kappa([qwks]))\n",
    "acc = np.sum(((coherence_prediction_LSTM - semantic_labels)==0)==True) / len(semantic_labels)\n",
    "print(\"acc \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZuNauj6aMEZ0"
   },
   "outputs": [],
   "source": [
    "def batch_iter_prompt(gold_data, gold_labels, gold_lengths, batch_size, num_epochs):\n",
    "\n",
    "    assert len(gold_data) == len(gold_labels) == len(gold_lengths)\n",
    "    data_size = len(gold_data)\n",
    "\n",
    "    epoch_length = data_size // batch_size\n",
    "  \n",
    "    for _ in range(num_epochs):\n",
    "        for i in range(epoch_length):\n",
    "            start_index = i * batch_size\n",
    "            end_index = start_index + batch_size\n",
    "\n",
    "            xdata = gold_data[start_index: end_index]\n",
    "            ydata = gold_labels[start_index: end_index]\n",
    "            sequence_length = gold_lengths[start_index: end_index]\n",
    "            \n",
    "            yield xdata, ydata, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EIdV9qu7LJ2J",
    "outputId": "4481ecf2-ec16-40b4-b50e-dc4fb67d0868"
   },
   "outputs": [],
   "source": [
    "# Prompt-related Model\n",
    "min_val = 0\n",
    "max_val = 12\n",
    "inference_graph = tf.Graph()\n",
    "res = np.array([])\n",
    "with tf.Session(graph = inference_graph) as sess:\n",
    "  \n",
    "    graph = tf.get_default_graph()\n",
    "    path = '/content/drive/My Drive/Prompt-related Model/runs/Bi-LSTM/'\n",
    "\n",
    "  \n",
    "    for i in range(3,4):\n",
    "        print(\"No.\" + str(i) + \" Model\\n\")\n",
    "        lstm_model = tf.train.import_meta_graph(os.path.join(path, \"Model_\"+str(i), \"model\", \"clf-500.meta\"))\n",
    "        lstm_model.restore(sess, tf.train.latest_checkpoint(os.path.join(path, \"Model_\"+str(i), \"model\")))\n",
    "    \n",
    "        x_dev = prompt_contents\n",
    "        y_dev = prompt_labels\n",
    "        dev_lengths = semantic_lengths\n",
    "\n",
    "        print('\\nDevlopment Set Validation ' + str(i))\n",
    "        dev_data = batch_iter_prompt(x_dev, y_dev, dev_lengths, 1783, 1)\n",
    "        for dev_input in dev_data:\n",
    "      \n",
    "          x_ = inference_graph.get_tensor_by_name('input_x:0')\n",
    "      y_ = inference_graph.get_tensor_by_name('input_y:0')\n",
    "      prediction_ = inference_graph.get_tensor_by_name('sigmoid/predictions:0')\n",
    "      keep_prob_ = inference_graph.get_tensor_by_name('keep_prob:0')\n",
    "      loss_ = inference_graph.get_tensor_by_name('loss/loss:0')\n",
    "      accuracy_ = inference_graph.get_tensor_by_name('accuracy/accuracy:0')\n",
    "      sequence_length_ = inference_graph.get_tensor_by_name('sequence_length:0')\n",
    "      batch_size_ = inference_graph.get_tensor_by_name('batch_size:0')\n",
    "      vars = sess.run([accuracy_, loss_, prediction_], \n",
    "                      feed_dict={x_: dev_input[0],\n",
    "                                 y_: dev_input[1],\n",
    "                                 keep_prob_: 1.0,\n",
    "                                 sequence_length_: dev_input[2],\n",
    "                                 batch_size_ : 1783})\n",
    "      time_str = datetime.datetime.now().isoformat()\n",
    "      res = np.concatenate((res, vars[2]), axis = 0)\n",
    "      print(vars[2])\n",
    "      print (dev_input[1])\n",
    "      qwks = score.quadratic_weighted_kappa((vars[2]).astype(int), dev_input[1], 2, 12)\n",
    "      print(\"qwks\",qwks,\" \", score.mean_quadratic_weighted_kappa([qwks]))\n",
    "      acc = np.sum(((vars[2]-dev_input[1])==0)==True) / len(vars[2])\n",
    "      print(\"{}: loss: {:g}, accuracy: {:g}\".format(time_str, vars[1], acc))\n",
    "      print('End Development Set Validation ' + str(i) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_Iee8w0JMtju"
   },
   "outputs": [],
   "source": [
    "prompt_prediction_LSTM = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BQZP4udfM5Cu"
   },
   "outputs": [],
   "source": [
    "prompt_prediction_Bi_LSTM = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "evIgs0B-ODYW"
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/My Drive/XGBoost Model/data/prompt_prediction_Bi_LSTM', prompt_prediction_Bi_LSTM)\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/prompt_prediction_LSTM', prompt_prediction_LSTM )\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/semantic_prediction_Bi_LSTM', semantic_prediction_Bi_LSTM )\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/semantic_prediction_LSTM', semantic_prediction_LSTM )\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/coherence_prediction_Bi_LSTM', coherence_prediction_Bi_LSTM )\n",
    "np.save('/content/drive/My Drive/XGBoost Model/data/coherence_prediction_LSTM', coherence_prediction_LSTM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CdPTqMFBbmNy"
   },
   "outputs": [],
   "source": [
    "prompt_prediction_Bi_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/prompt_prediction_Bi_LSTM.npy')\n",
    "prompt_prediction_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/prompt_prediction_LSTM.npy')\n",
    "semantic_prediction_Bi_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/semantic_prediction_Bi_LSTM.npy')\n",
    "semantic_prediction_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/semantic_prediction_LSTM.npy')\n",
    "coherence_prediction_Bi_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/coherence_prediction_Bi_LSTM.npy')\n",
    "coherence_prediction_LSTM = np.load('/content/drive/My Drive/XGBoost Model/data/coherence_prediction_LSTM.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZkFu0yoEHtIU"
   },
   "outputs": [],
   "source": [
    "labels = np.load('/content/drive/My Drive/Semantic Model/word embedding/set1_label.npy')\n",
    "labels = labels - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qt3sKIWpT6TQ"
   },
   "outputs": [],
   "source": [
    "# prompt_prediction_Bi_LSTM = (prompt_prediction_Bi_LSTM - min(prompt_prediction_Bi_LSTM)) / (max(prompt_prediction_Bi_LSTM) - min(prompt_prediction_Bi_LSTM))\n",
    "# semantic_prediction_Bi_LSTM = (semantic_prediction_Bi_LSTM - min(semantic_prediction_Bi_LSTM)) / (max(semantic_prediction_Bi_LSTM) - min(semantic_prediction_Bi_LSTM))\n",
    "# coherence_prediction_Bi_LSTM = (coherence_prediction_Bi_LSTM - min(coherence_prediction_Bi_LSTM)) / (max(coherence_prediction_Bi_LSTM) - min(coherence_prediction_Bi_LSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yr8-DYsnW8jr"
   },
   "outputs": [],
   "source": [
    "# prompt_prediction_Bi_LSTM = (prompt_prediction_Bi_LSTM - 2) / (12 - 2)\n",
    "# semantic_prediction_Bi_LSTM = semantic_prediction_Bi_LSTM * 10 + 2\n",
    "# coherence_prediction_Bi_LSTM = (coherence_prediction_Bi_LSTM - 2) / (12 - 2)\n",
    "semantic_prediction_LSTM = semantic_prediction_LSTM * 10 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2VgOsy84SrG-"
   },
   "outputs": [],
   "source": [
    "prompt_prediction_Bi_LSTM = prompt_prediction_Bi_LSTM.reshape(len(prompt_prediction_Bi_LSTM), 1)\n",
    "semantic_prediction_Bi_LSTM = semantic_prediction_Bi_LSTM.reshape(len(semantic_prediction_Bi_LSTM), 1)\n",
    "coherence_prediction_Bi_LSTM = coherence_prediction_Bi_LSTM.reshape(len(coherence_prediction_Bi_LSTM), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iG3jFxNaVt23"
   },
   "outputs": [],
   "source": [
    "prompt_prediction_LSTM = prompt_prediction_LSTM.reshape(len(prompt_prediction_LSTM), 1)\n",
    "semantic_prediction_LSTM = semantic_prediction_LSTM.reshape(len(semantic_prediction_LSTM), 1)\n",
    "coherence_prediction_LSTM = coherence_prediction_LSTM.reshape(len(coherence_prediction_LSTM), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CIFafArhSTDp"
   },
   "outputs": [],
   "source": [
    "final_data_Bi_LSTM = np.concatenate((hf, prompt_prediction_LSTM - 2, semantic_prediction_LSTM - 2, coherence_prediction_LSTM - 2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bKAW1Yhts5bz"
   },
   "outputs": [],
   "source": [
    "final_data_Bi_LSTM = hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g7gggWvHR_T7"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "unit = int(len(final_data_Bi_LSTM) / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3Nucxx1WGCy"
   },
   "source": [
    "使用 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yL0JG3fvWD5H"
   },
   "outputs": [],
   "source": [
    "# 80%训练集，20%测试集\n",
    "train_dataset = []\n",
    "train_label = []\n",
    "\n",
    "dev_dataset = []\n",
    "dev_label = []\n",
    "\n",
    "test_dataset = []\n",
    "test_label = []\n",
    "\n",
    "train_dataset = final_data_Bi_LSTM[0: 4 * unit]\n",
    "train_label = labels[0: 4 * unit]\n",
    "\n",
    "test_dataset = final_data_Bi_LSTM[4 * unit: -1]\n",
    "test_label = labels[4 * unit: -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_uR6X_ItK0tu",
    "outputId": "29917daa-7ce2-453e-a9d1-c2d824f6de89"
   },
   "outputs": [],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HXqrH0UrVgLC"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_dataset, train_label)\n",
    "dtest = xgb.DMatrix(test_dataset, test_label)\n",
    "eval_list = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "param = {'booster': 'gbtree', 'bst: max_depth': 6, 'bst:eta': 0.001, 'objective': 'multi:softmax', 'num_class': 11}\n",
    "epoch_nums = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1003
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "rPPl2upOIqWV",
    "outputId": "54884c90-d65d-4fd4-c8a6-46b4e3cd1a0a"
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(param.items(), dtrain, epoch_nums, eval_list, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1-z6YO5WftHh"
   },
   "outputs": [],
   "source": [
    "test = xgb.DMatrix(test_dataset)\n",
    "ypred = bst.predict(test, ntree_limit=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JRaQv0Spfbh4",
    "outputId": "98ab442b-b3c1-457a-b130-d7ed5c678024"
   },
   "outputs": [],
   "source": [
    "# np.sum(((np.squeeze(np.round(semantic_prediction_Bi_LSTM)) - (labels + 2))==0)==True) / 178\n",
    "np.sum((((ypred+2) - (test_label + 2))==0)==True) / len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gE14xpeIKC1X",
    "outputId": "85699b68-778b-4787-9f88-85aaf2ab9eea"
   },
   "outputs": [],
   "source": [
    "score.quadratic_weighted_kappa((ypred+2).astype(int), test_label+2, 2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "BM0XOB-zYdye",
    "outputId": "13e8b73e-9e20-48f0-de05-bccb6d0cd009"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(semantic_prediction_Bi_LSTM, labels+2, 'ro', markersize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uh5DZrqyYvpT",
    "outputId": "eff8642e-e949-4ba1-8c9b-b3effde20e13"
   },
   "outputs": [],
   "source": [
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zBwiRmH4f7ac"
   },
   "outputs": [],
   "source": [
    "bst.save_model('xgboost_01.model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XGBoost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
